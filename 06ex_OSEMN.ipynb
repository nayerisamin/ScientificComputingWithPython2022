{
<<<<<<< HEAD
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gBF5ZCyVz7mh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmdY-OfVz7mk"
      },
      "source": [
        "1\\. **Text files**\n",
        "\n",
        "Perform the following operations on plain `txt` files:\n",
        "\n",
        "+ create a list of integrer numbers and then save it to a text file named `data_int.txt`. Run the `cat` command to print the content of the file.\n",
        "+ create a matrix of 5x5 floats and then save it to a text file named `data_float.txt`. Use the `cat` command to print the content of the file.\n",
        "+ load the `txt` file of the previous point and convert it to a `csv` file by hand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxBGBcgcz7mn",
        "outputId": "0ac7b224-4f08-4201-ff02-18b34b01e3b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "3\n",
            "6\n",
            "1\n",
            "6\n",
            "10\n",
            "3\n",
            "2\n",
            "5\n",
            "6\n",
            "10\n",
            "0\n",
            "4\n",
            "5\n",
            "7\n",
            "6\n",
            "10\n",
            "10\n",
            "2\n",
            "4\n",
            "12\n",
            "12\n",
            "3\n",
            "2\n",
            "4\n",
            "11\n",
            "2\n",
            "10\n",
            "0\n",
            "5\n",
            "3\n",
            "2\n",
            "3\n",
            "0\n",
            "11\n",
            "2\n",
            "1\n",
            "4\n",
            "4\n",
            "6\n",
            "12\n",
            "1\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "0\n",
            "5\n",
            "10\n",
            "3\n",
            "1\n",
            "0\n",
            "11\n",
            "8\n",
            "10\n",
            "12\n",
            "5\n",
            "1\n",
            "89.230746754709040491e-02 4.075391703597808224e-01 5.942489111783810785e-02 2.991328497647205431e-01 8.338351035981358406e-01\n",
            "3.135346191989858422e-01 4.498369925642069500e-01 6.033722411489951254e-01 9.801567085744630203e-01 3.469464956777444931e-01\n",
            "2.767518032358825542e-01 1.512512571430713049e-01 3.000653432354356553e-01 1.728263311364103272e-01 3.370127530749426059e-01\n",
            "1.872527897018874121e-01 7.853244349219128395e-01 5.984879767963535713e-02 2.878377852207938403e-01 1.285020019638878352e-01\n",
            "2.337566007905237386e-01 9.086782456081079484e-01 1.789516158556987424e-01 5.652722081172906199e-01 1.717768725169993571e-01\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "list = []\n",
        "for i in range(0, 59):\n",
        "    n = random.randint(0, 12)\n",
        "    list.append(n)\n",
        "with open('data_int.txt', 'w') as file:\n",
        "    file.write('\\n'.join(str(number) for number in list))\n",
        "\n",
        "!cat data_int.txt\n",
        "\n",
        "matrix = np.random.rand(5, 5)\n",
        "mat = np.matrix(matrix)\n",
        "with open('data_float.txt', 'w') as file:\n",
        "    for row in mat:\n",
        "        np.savetxt(file, row)\n",
        "\n",
        "!cat data_float.txt\n",
        "\n",
        "import csv\n",
        "\n",
        "with open('data_float.txt', 'r') as file:\n",
        "    load = (line.strip() for line in file)\n",
        "    lines = (line.split(\",\") for line in load if line)\n",
        "    with open('data_float.csv', 'w') as out_file:\n",
        "        writer = csv.writer(out_file)\n",
        "        writer.writerow(('SUBJECT', 'INTRODUCTION'))\n",
        "        writer.writerows(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwLLvkV9z7mp"
      },
      "source": [
        "2\\. **JSON files**\n",
        "\n",
        "Load the file *user_data.json*, which can be found at:\n",
        "\n",
        "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
        "\n",
        "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdtDRmYY2hE7",
        "outputId": "d8c79b7d-632c-4e8f-972e-70bd480654f6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-02 21:10:16--  https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/sz5klcdpckc39hd/user_data.json [following]\n",
            "--2022-12-02 21:10:16--  https://www.dropbox.com/s/raw/sz5klcdpckc39hd/user_data.json\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucae1224d346d868e9430894b6a5.dl.dropboxusercontent.com/cd/0/inline/Bx4xdl6_hAOdKCoSBfyZsT1kZ3xtk72fDYtQ2PBYb6BtGjqsH9KtJcaK9s1PCqq0y_oV9CFmPwF0_ClfAffIalIcOiSIiUCXpaTS53oaOvoWVk33JY-7ke4IpqnRsolZq89XVO4wIu1NttMRfCzWYsnt_40SLJwyloYuCluEWoom3Q/file# [following]\n",
            "--2022-12-02 21:10:17--  https://ucae1224d346d868e9430894b6a5.dl.dropboxusercontent.com/cd/0/inline/Bx4xdl6_hAOdKCoSBfyZsT1kZ3xtk72fDYtQ2PBYb6BtGjqsH9KtJcaK9s1PCqq0y_oV9CFmPwF0_ClfAffIalIcOiSIiUCXpaTS53oaOvoWVk33JY-7ke4IpqnRsolZq89XVO4wIu1NttMRfCzWYsnt_40SLJwyloYuCluEWoom3Q/file\n",
            "Resolving ucae1224d346d868e9430894b6a5.dl.dropboxusercontent.com (ucae1224d346d868e9430894b6a5.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6021:15::a27d:410f\n",
            "Connecting to ucae1224d346d868e9430894b6a5.dl.dropboxusercontent.com (ucae1224d346d868e9430894b6a5.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40417 (39K) [text/plain]\n",
            "Saving to: ‘user_data.json’\n",
            "\n",
            "user_data.json      100%[===================>]  39.47K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2022-12-02 21:10:17 (8.09 MB/s) - ‘user_data.json’ saved [40417/40417]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "info = json.load(open('user_data.json'))"
      ],
      "metadata": {
        "id": "TznXJVQM2mfa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tEqXXMaz7mr",
        "outputId": "24221b04-458e-4835-8f85-6a7564f4cec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{\"ID\": \"2\", \"JobTitle\": \"Investment  Advisor\", \"EmailAddress\": \"Clint_Thorpe5003@bulaffy.com\", \"FirstNameLastName\": \"Clint Thorpe\", \"CreditCard\": \"7083-8766-0251-2345\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"12\", \"JobTitle\": \"Retail Trainee\", \"EmailAddress\": \"Phillip_Carpenter9505@famism.biz\", \"FirstNameLastName\": \"Phillip Carpenter\", \"CreditCard\": \"3657-0088-0820-5247\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"28\", \"JobTitle\": \"Project Manager\", \"EmailAddress\": \"Russel_Graves1378@extex.org\", \"FirstNameLastName\": \"Russel Graves\", \"CreditCard\": \"6718-4818-8011-6024\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"39\", \"JobTitle\": \"Stockbroker\", \"EmailAddress\": \"Leanne_Newton1268@typill.biz\", \"FirstNameLastName\": \"Leanne Newton\", \"CreditCard\": \"5438-0816-4166-4847\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"57\", \"JobTitle\": \"Budget Analyst\", \"EmailAddress\": \"Tony_Giles1960@iatim.tech\", \"FirstNameLastName\": \"Tony Giles\", \"CreditCard\": \"8130-3425-7573-7745\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"62\", \"JobTitle\": \"CNC Operator\", \"EmailAddress\": \"Owen_Allcott5125@bauros.biz\", \"FirstNameLastName\": \"Owen Allcott\", \"CreditCard\": \"4156-0107-7210-2630\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"68\", \"JobTitle\": \"Project Manager\", \"EmailAddress\": \"Liam_Lynn3280@kideod.biz\", \"FirstNameLastName\": \"Liam Lynn\", \"CreditCard\": \"7152-3247-6053-2233\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"74\", \"JobTitle\": \"Dentist\", \"EmailAddress\": \"Regina_Woodcock5820@yahoo.com\", \"FirstNameLastName\": \"Regina Woodcock\", \"CreditCard\": \"0208-1753-3870-8002\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"81\", \"JobTitle\": \"HR Specialist\", \"EmailAddress\": \"Carter_Wallace9614@atink.com\", \"FirstNameLastName\": \"Carter Wallace\", \"CreditCard\": \"4256-7201-6717-4322\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"92\", \"JobTitle\": \"Staffing Consultant\", \"EmailAddress\": \"Maia_Stark2797@jiman.org\", \"FirstNameLastName\": \"Maia Stark\", \"CreditCard\": \"3851-1403-1734-6321\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"97\", \"JobTitle\": \"Stockbroker\", \"EmailAddress\": \"Ciara_Lomax982@bauros.biz\", \"FirstNameLastName\": \"Ciara Lomax\", \"CreditCard\": \"3702-3440-2472-5424\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"116\", \"JobTitle\": \"Staffing Consultant\", \"EmailAddress\": \"Isabel_Ellwood1475@fuliss.net\", \"FirstNameLastName\": \"Isabel Ellwood\", \"CreditCard\": \"3738-0882-0066-6683\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"148\", \"JobTitle\": \"CNC Operator\", \"EmailAddress\": \"Abdul_Townend2202@infotech44.tech\", \"FirstNameLastName\": \"Abdul Townend\", \"CreditCard\": \"4224-1226-3557-3448\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"150\", \"JobTitle\": \"Fabricator\", \"EmailAddress\": \"Caleb_Poulton1735@atink.com\", \"FirstNameLastName\": \"Caleb Poulton\", \"CreditCard\": \"8203-6875-5225-0341\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"151\", \"JobTitle\": \"Restaurant Manager\", \"EmailAddress\": \"Ronald_Lewis6777@deavo.com\", \"FirstNameLastName\": \"Ronald Lewis\", \"CreditCard\": \"7212-0155-5014-8471\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"154\", \"JobTitle\": \"Bellman\", \"EmailAddress\": \"Faith_Seymour3829@twace.org\", \"FirstNameLastName\": \"Faith Seymour\", \"CreditCard\": \"4170-5186-6887-6558\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"169\", \"JobTitle\": \"Assistant Buyer\", \"EmailAddress\": \"Anthony_Hancock9083@qater.org\", \"FirstNameLastName\": \"Anthony Hancock\", \"CreditCard\": \"0832-3357-6010-6550\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"176\", \"JobTitle\": \"Healthcare Specialist\", \"EmailAddress\": \"Isabella_Willson5478@nanoff.biz\", \"FirstNameLastName\": \"Isabella Willson\", \"CreditCard\": \"5177-4868-4623-0384\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"182\", \"JobTitle\": \"Pharmacist\", \"EmailAddress\": \"Stephanie_Darcy3298@bauros.biz\", \"FirstNameLastName\": \"Stephanie Darcy\", \"CreditCard\": \"0264-4020-5106-5576\", \"CreditCardType\": \"American Express\"}, {\"ID\": \"199\", \"JobTitle\": \"Investment  Advisor\", \"EmailAddress\": \"Ryan_Kennedy5565@corti.com\", \"FirstNameLastName\": \"Ryan Kennedy\", \"CreditCard\": \"3166-6287-6242-7207\", \"CreditCardType\": \"American Express\"}]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "filter = [x for x in info if x['CreditCardType'] == 'American Express']\n",
        "output = json.dumps(filter)\n",
        "print(output)\n",
        "\n",
        "newformat = pd.DataFrame(eval(output))\n",
        "newformat.to_csv('user_data.csv', index=False,header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMYmnMgXz7ms"
      },
      "source": [
        "3\\. **CSV files with Pandas**\n",
        "\n",
        "Load the file from this url:\n",
        "\n",
        "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
        "\n",
        "with Pandas. \n",
        "\n",
        "+ explore and print the DataFrame\n",
        "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
        "+ save the file in a JSON format."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhOVwaMB65P5",
        "outputId": "63bd2e33-40cf-40aa-aa41-9a84ce87e117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-02 17:39:13--  https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/kgshemfgk22iy79/mushrooms_categorized.csv [following]\n",
            "--2022-12-02 17:39:13--  https://www.dropbox.com/s/raw/kgshemfgk22iy79/mushrooms_categorized.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc62db79c5c2d6c19dce5941615d.dl.dropboxusercontent.com/cd/0/inline/Bx32DUEJcHz9h5kFfkmTamI8H40_NXsmEbSb857zm6larQVgV_abksNJVadBUVFgIBqvQkVvzuMCZiSg6C_kcFXbAYBWj_k-uosO4HO5T82GJ68SojDtwoCV_53KeO6ZRVq5k_P-zJMzsEf5eER6qx0w4k3peA6zKp5uqM5-ssoPLw/file# [following]\n",
            "--2022-12-02 17:39:13--  https://uc62db79c5c2d6c19dce5941615d.dl.dropboxusercontent.com/cd/0/inline/Bx32DUEJcHz9h5kFfkmTamI8H40_NXsmEbSb857zm6larQVgV_abksNJVadBUVFgIBqvQkVvzuMCZiSg6C_kcFXbAYBWj_k-uosO4HO5T82GJ68SojDtwoCV_53KeO6ZRVq5k_P-zJMzsEf5eER6qx0w4k3peA6zKp5uqM5-ssoPLw/file\n",
            "Resolving uc62db79c5c2d6c19dce5941615d.dl.dropboxusercontent.com (uc62db79c5c2d6c19dce5941615d.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to uc62db79c5c2d6c19dce5941615d.dl.dropboxusercontent.com (uc62db79c5c2d6c19dce5941615d.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 375292 (366K) [text/plain]\n",
            "Saving to: ‘mushrooms_categorized.csv.1’\n",
            "\n",
            "mushrooms_categoriz 100%[===================>] 366.50K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-12-02 17:39:14 (10.5 MB/s) - ‘mushrooms_categorized.csv.1’ saved [375292/375292]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "!wget https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVluvo_mrmst",
        "outputId": "46c37a79-9600-4e2d-df41-5cc49d28cc02"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-02 21:12:04--  https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/kgshemfgk22iy79/mushrooms_categorized.csv [following]\n",
            "--2022-12-02 21:12:04--  https://www.dropbox.com/s/raw/kgshemfgk22iy79/mushrooms_categorized.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucba15c0511c24ad58158e27ca5b.dl.dropboxusercontent.com/cd/0/inline/Bx7vSmyxNWxAnzJsi_CZWiYGuU8rHwJ9aV3tC2s1ohu-B6pfUXwGjMMAJFlqBDxUDRpmOvrULz5sFArZxLZ8RLOLQjS_M8-uaaab7VNq49CpltB3RXkwVjTZ6yGhNWxE2qIxWQL6V8dL5v8WxPhTuuvyMuHVNK-a1I6iWPAgMR_jvQ/file# [following]\n",
            "--2022-12-02 21:12:05--  https://ucba15c0511c24ad58158e27ca5b.dl.dropboxusercontent.com/cd/0/inline/Bx7vSmyxNWxAnzJsi_CZWiYGuU8rHwJ9aV3tC2s1ohu-B6pfUXwGjMMAJFlqBDxUDRpmOvrULz5sFArZxLZ8RLOLQjS_M8-uaaab7VNq49CpltB3RXkwVjTZ6yGhNWxE2qIxWQL6V8dL5v8WxPhTuuvyMuHVNK-a1I6iWPAgMR_jvQ/file\n",
            "Resolving ucba15c0511c24ad58158e27ca5b.dl.dropboxusercontent.com (ucba15c0511c24ad58158e27ca5b.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6021:15::a27d:410f\n",
            "Connecting to ucba15c0511c24ad58158e27ca5b.dl.dropboxusercontent.com (ucba15c0511c24ad58158e27ca5b.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 375292 (366K) [text/plain]\n",
            "Saving to: ‘mushrooms_categorized.csv’\n",
            "\n",
            "mushrooms_categoriz 100%[===================>] 366.50K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-12-02 21:12:05 (22.3 MB/s) - ‘mushrooms_categorized.csv’ saved [375292/375292]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZlgyGAcz7mt",
        "outputId": "1f5701ac-9068-4637-e7bf-0091c9134435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       cap-shape  cap-surface  cap-color   bruises      odor  gill-attachment  \\\n",
            "class                                                                           \n",
            "0       3.266160     1.615970   4.581749  0.653992  4.334601         0.954373   \n",
            "1       3.436159     2.055158   4.421859  0.159346  3.940756         0.995403   \n",
            "\n",
            "       gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
            "class                                                    ...   \n",
            "0          0.285171   0.068441    6.622624     0.615970  ...   \n",
            "1          0.028601   0.567926    2.863636     0.514811  ...   \n",
            "\n",
            "       stalk-surface-below-ring  stalk-color-above-ring  \\\n",
            "class                                                     \n",
            "0                      1.798479                6.098859   \n",
            "1                      1.394280                5.512768   \n",
            "\n",
            "       stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
            "class                                                                          \n",
            "0                    6.064639        0.0    1.931559     1.125475   3.007605   \n",
            "1                    5.504597        0.0    2.002043     1.009193   1.522983   \n",
            "\n",
            "       spore-print-color  population   habitat  \n",
            "class                                           \n",
            "0               3.201521    3.283270  1.148289  \n",
            "1               4.021450    4.031665  1.895812  \n",
            "\n",
            "[2 rows x 22 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x = pd.read_csv(\"mushrooms_categorized.csv\")\n",
        "calculate = x.groupby('class')\n",
        "print(calculate.mean())\n",
        "\n",
        "calculate.mean().reset_index().to_json('mushrooms_categorized.json')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOnkKnq5z7mt"
      },
      "source": [
        "4\\. **Reading the credit card numbers**\n",
        "\n",
        "Get the binary file named *credit_card.dat* from this address:\n",
        "\n",
        "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
        "\n",
        "and convert the data into the real credit card number, knowing that:\n",
        "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
        "- each character is written using a 6 bit binary representation (including the whitespace)\n",
        "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
        "\n",
        "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02ZZ9jGGz7mv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1flloPDVz7mw"
      },
      "source": [
        "5\\. **Write data to a binary file**\n",
        "\n",
        "a) Start from the `data/data_000637.txt` file that we have used during the previous lectures, and convert it to a binary file according to the format defined below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfqmRKHQz7my"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "Image(\"images/data_format.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK_p5mxwz7mz"
      },
      "source": [
        "*Hints*:\n",
        "- Read the first 10 lines using Pandas\n",
        "- Iterate over the DataFrame rows\n",
        "- For every row, ``pack'' the values (features) into a single 64-bit word, according to the format specified above. Use bit-wise shifts and operators to do so.\n",
        "- Write each 64-bit word to a binary file. You can use `struct` in this way:\n",
        "```\n",
        "binary_file.write( struct.pack('<q', word) )\n",
        "```\n",
        "where `word` is the 64-bit word.\n",
        "- Close the file after completing the loop.\n",
        "\n",
        "b) Check that the binary file is correctly written by reading it with the code used in the lecture `06_OSEMN.ipynb`, and verify that the content of the `txt` and binary files is consistent.\n",
        "\n",
        "c) What is the difference of the size on disk between equivalent `txt` and binary files?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dluOOf1lz7mz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsXmaN-Rz7m0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
=======
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Text files**\n",
    "\n",
    "Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named `data_int.txt`. Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named `data_float.txt`. Use the `cat` command to print the content of the file.\n",
    "+ load the `txt` file of the previous point and convert it to a `csv` file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **JSON files**\n",
    "\n",
    "Load the file *user_data.json*, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **CSV files with Pandas**\n",
    "\n",
    "Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **Reading the credit card numbers**\n",
    "\n",
    "Get the binary file named *credit_card.dat* from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Write data to a binary file**\n",
    "\n",
    "a) Start from the `data/data_000637.txt` file that we have used during the previous lectures, and convert it to a binary file according to the format defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/data_format.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Read the first 10 lines using Pandas\n",
    "- Iterate over the DataFrame rows\n",
    "- For every row, ``pack'' the values (features) into a single 64-bit word, according to the format specified above. Use bit-wise shifts and operators to do so.\n",
    "- Write each 64-bit word to a binary file. You can use `struct` in this way:\n",
    "```\n",
    "binary_file.write( struct.pack('<q', word) )\n",
    "```\n",
    "where `word` is the 64-bit word.\n",
    "- Close the file after completing the loop.\n",
    "\n",
    "b) Check that the binary file is correctly written by reading it with the code used in the lecture `06_OSEMN.ipynb`, and verify that the content of the `txt` and binary files is consistent.\n",
    "\n",
    "c) What is the difference of the size on disk between equivalent `txt` and binary files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
>>>>>>> main
